import pandas as pd 
import seaborn as sns 
import streamlit as st 
import matplotlib.pyplot as plt 
import numpy as np 
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
import statsmodels.api
import statsmodels.api as sm
import scipy.stats as stats
import xgboost as xgb
import shap
from scipy.stats import norm, ttest_ind
from sklearn import preprocessing
from sklearn.linear_model import LinearRegression, ElasticNetCV
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from xgboost import XGBRegressor, plot_importance

st.set_page_config(page_title="R√©gression", page_icon="üìà")
st.sidebar.header("R√©gression")

# Cacher "Made with Streamlit"
hide_footer_style = """ 
    <style>
    footer {visibility: hidden; }
    </style>
    """
st.markdown(hide_footer_style, unsafe_allow_html=True)

# Image CO2
from PIL import Image
image = Image.open('CO2_wide.jpg')
st.image(image)

# Titre
st.title("Machine Learning")
    
# Partie R√©gression
st.header("R√©gression")
st.write("En aval du pre-processing, **les variables cat√©gorielles ont √©t√© dichotomis√©es** pour la mod√©lisation et les variables de masse et d'√©mission de CO‚ÇÇ selon la norme NEDC supprim√©es (pour cette pr√©sentation Streamlit, on ne s'int√©ressera qu'√† la norme WLTP afin d'acc√©l√©rer l'ex√©cution des scripts).")

# Import dataset
cars = pd.read_csv("C:/Users/lebre/Documents/Jupyter Notebook/Projet CO2/Data/cars_FR2019_clean.csv", index_col=0)


### Preprocessing 

# Dichotomisation des variables qualitatives sur le jeu de donn√©es entier
list_quali  = ['At2supAt1','IT', 'Ft', 'Fm', 'Cr', 'Mp']
list_quanti = ['m', 'Mt', 'At1', 'W', 'ec', 'ep', 'Enedc', 'Ewltp']

# choix de la modalit√© de r√©f√©rence
cars_dummies = pd.get_dummies(cars[list_quali], columns = list_quali).drop(['At2supAt1_0',
                                                                            'IT_0',
                                                                            'Ft_petrol',
                                                                            'Fm_mono_fuel',
                                                                            'Cr_M1',
                                                                            'Mp_BMW GROUP'],axis=1)
cars_lm = cars[list_quanti]
cars_lm = pd.concat([cars[list_quanti], cars_dummies], axis=1)
cars_lm = cars_lm.drop(['m', 'Enedc'], axis=1)
    
st.subheader("Affichage des features et target")
    
# S√©paration des donn√©es
target_wltp = cars['Ewltp']
feats_wltp = cars_lm.drop(['Ewltp'], axis=1)

# Renommer les variables
rename = {'Mt': 'Masse test (kg)',
          'ec': 'Cylindr√©e en cm3',
          'ep': 'Puissance moteur en KW',
          'Ewltp': 'Emissions de CO2 en g/km',
          'Ft': 'Type de carburant',
          'Fm': 'Mode de carburation',
          'Ft_diesel': 'Diesel',
          'Fm_NOVC-HEV': 'Hybride non-rechargeable',
          'Fm_OVC-HEV': 'Hybride rechargeable',
          'IT_1': 'Eco-innovation',
          'W': 'Empattement en mm',
          'At1': "Largeur de voie essieu directeur (mm)",
          'At2supAt1_1': 'Essieu arri√®re sup√©rieur essieu avant',
          'Cr_M1G': 'Motricit√© (4x4)'}
cars_lm_rename = cars_lm.rename(rename,axis=1)

# Fonction pour surligner des valeurs dans le dataframe
def color_df(val):
    if val > 0:
        color = '#97FF9A'
    if val > 143:
        color = '#FBFF61'
    if val > 160:
        color = '#FFB24D'
    if val > 190:
        color = '#FF4D4D'
    return f'background-color: {color}'

### Affichage du dataframe
line_to_plot = st.slider("S√©lectionnez le nombre de lignes √† afficher", min_value=3, max_value=1000)

if st.sidebar.checkbox("Renommer les variables"):
    st.dataframe(cars_lm_rename.head(line_to_plot).style.applymap(color_df, subset=['Emissions de CO2 en g/km']))
    feats_wltp = feats_wltp.rename(rename, axis=1)
else:
    st.dataframe(cars_lm.head(line_to_plot).style.applymap(color_df, subset=['Ewltp']))

# S√©lection des features
options = st.multiselect('Choisissez les features :', options=feats_wltp.columns, default=feats_wltp.columns.values)
    

col1, col2 = st.columns(2)
with col1:
    # Choix du mod√®le
    model = st.radio(
        "Choisissez un mod√®le :",
        ('R√©gression lin√©aire', 'R√©gression lin√©aire r√©gularis√©e (ElasticNet)', 'XGBoost'))
with col2:
    # select how to split the data
    train_size_wltp = st.slider(label = "Choix de la taille de l'√©chantillon d'entrainement",
                                        min_value = 0.70, max_value = 0.90, step = 0.01)

# S√©paration des donn√©es
X_wltp_train, X_wltp_test, y_wltp_train, y_wltp_test = train_test_split(feats_wltp[options], target_wltp,
                                                                        train_size=train_size_wltp,
                                                                        random_state=33)
# normalisation des donn√©es
sc_wltp = preprocessing.StandardScaler()
X_wltp_scaled_train = pd.DataFrame(sc_wltp.fit_transform(X_wltp_train),
                                   columns = X_wltp_train.columns,
                                   index = X_wltp_train.index)
X_wltp_scaled_test = pd.DataFrame(sc_wltp.transform(X_wltp_test),
                                  columns = X_wltp_test.columns,
                                  index = X_wltp_test.index)

# R√©gression lin√©aire
if model == 'R√©gression lin√©aire':
    st.subheader("R√©gression lin√©aire")
    st.write("Un mod√®le de base a √©t√© produit √† partir d‚Äôune r√©gression lin√©aire multiple **sans s√©lection de variables et sans param√©trage particulier**. Les hypoth√®ses de normalit√© et d‚Äôhomosc√©dasticit√© des r√©sidus ont √©t√© test√©es sur ce mod√®le de base.")

    lr_wltp = LinearRegression()
    lr_wltp.fit(X_wltp_scaled_train, y_wltp_train)
    col1, col2, col3 = st.columns(3)
    with col1:
        st.write('  - R¬≤ train :', lr_wltp.score(X_wltp_scaled_train, y_wltp_train).round(3))
        st.write('  - R¬≤ test :', lr_wltp.score(X_wltp_scaled_test,y_wltp_test).round(3))
    lr_wltp_pred_train = lr_wltp.predict(X_wltp_scaled_train)
    lr_wltp_pred_test = lr_wltp.predict(X_wltp_scaled_test)
    with col2:
        st.write('  - RMSE train :', np.sqrt(mean_squared_error(lr_wltp_pred_train, y_wltp_train)).round(3))
        st.write('  - RMSE test :', np.sqrt(mean_squared_error(lr_wltp_pred_test, y_wltp_test)).round(3))
    with col3:
        st.write('  - MAE train :', mean_absolute_error(lr_wltp_pred_train, y_wltp_train).round(3))
        st.write('  - MAE test :', mean_absolute_error(lr_wltp_pred_test, y_wltp_test).round(3))
    
    st.write("Les performances globales du mod√®le sont **√©lev√©es** : le coefficient de d√©termination est aux alentours de **0,89** sur les donn√©es d'entra√Ænement et de test (faire varier la taille du jeu d'entra√Ænement pour obtenir la meilleure performance possible). **Le mod√®le ne semble pas souffrir de sur-apprentissage** avec des √©carts quadratiques moyens (RMSE) relativement faibles entre les jeux d'entra√Ænement et de test.")
    
    
    
    ## points influents et significativit√© des coefficients avec statsmodel 
    y = y_wltp_train
    x = X_wltp_scaled_train

    # entrainement du mod√®le de r√©gression lin√©aire
    model_wltp = sm.OLS(y, sm.add_constant(x, prepend=False)).fit()
    print(model_wltp.summary())

    
    # Analyse des r√©sidus
    st.write('\n')
    st.markdown("#### Analyse des r√©sidus : Normalit√© et homosc√©dasticit√©")
    st.write("Si l‚Äôhypoth√®se de normalit√© peut √™tre retenue, la variabilit√© des r√©sidus est clairement d√©pendante des valeurs d‚Äô√©mission de CO2 avec une variabilit√© plus √©lev√©e pour les valeurs hautes et basses.")
    
    ## histogramme
    st.set_option('deprecation.showPyplotGlobalUse', False)
    fig = plt.figure(figsize=(7,5.2))
    plt.hist(model_wltp.resid, bins=50)
    plt.title('normalit√© - histogramme\n')

    ## Normalit√©
    # les tests de Jarques Bera et Omnibus produits dans les r√©sultats indiquent que l'hypoth√®se de normalit√© est rejett√©e (p<0.5)
    # le QQ plot permet une repr√©sentation visuelle qui montre toutefois que les r√©sultats sont corrects

    residus_std = model_wltp.resid_pearson # r√©sidus standardis√©s
    fig2 = sm.qqplot(residus_std, stats.t, fit=True,line='45')
    
    plt.xlabel("Quantiles th√©oriques")
    plt.ylabel("Quantiles observ√©s")

    plt.title("normalit√© - QQ plot\n")
    
    col1, col2 = st.columns(2)
    col1.pyplot(fig, use_container_width=True)
    col2.pyplot(fig2, use_container_width=True)
    
        
    ## Homosc√©dasticit√©
    st.write("Le test de Breush-Pagan confirme que l‚Äôhypoth√®se d‚Äôhomosc√©dasticit√© ne peut √™tre retenue. L‚Äôallure du nuage de points indique que le mod√®le pr√©dit moins bien les taux d‚Äô√©mission des v√©hicules avec des faibles ou des fortes valeurs.")
    
    lagrande, pval, f, fpval = statsmodels.stats.diagnostic.het_breuschpagan(model_wltp.resid, model_wltp.model.exog)
    print("Test d'homosc√©dasticit√© des r√©sidus (Breush-Pagan)")
    print('f-statistic', f.round(6), '\np-value for the f-statistic', fpval)
    plt.figure(figsize=(7,3))
    plt.scatter(y,residus_std, s=2)

    plt.title("homosc√©dasticit√©\n")
    plt.xlabel("Emission de CO2")
    plt.ylabel("R√©sidus")
    st.pyplot()


    # analyse graphique de l'influence √† partir de la distance de Cook
    st.markdown("#### Analyse de l'influence gr√¢ce √† la distance de Cook")
    st.write("La repr√©sentation des distances de Cook permet d‚Äôidentifier trois v√©hicules particuli√®rement atypiques : il s‚Äôagit de trois diff√©rentes versions de la Lamborghini Avantador, un v√©hicule aux caract√©ristiques techniques effectivement hors norme. La r√©gression lin√©aire √©tant tr√®s sensible aux valeurs extr√™mes, ces v√©hicules ont √©t√© exclus du dataset d'entra√Ænement. N√©anmoins, on note que l‚Äôinfluence de certains v√©hicules dans l‚Äôestimation des coefficients de r√©gression reste tr√®s marqu√©e.")
    
    influence = model_wltp.get_influence()
    (c, p) = influence.cooks_distance # c : distance et p : p-value
    plt.figure(figsize=(7,2))
    plt.stem(np.arange(len(c)), c, markerfmt=",")
    plt.ylim(0,0.12)
    # plt.axhline(y = 3*c.mean(),color="r",linewidth=1)

    plt.title('Points influents : Dataset complet')
    plt.ylabel('Distance de Cook')
    st.pyplot()

    # visualisation des 3 points tr√®s influents
    df_cooks = pd.DataFrame(c, columns = ['cook'], index = X_wltp_scaled_train.index)
    ind = df_cooks.loc[df_cooks['cook']>0.08].index
    cars[['Mh','Cn', 'Ewltp', 'ec', 'ep', 'Mt']].loc[ind]
    
    # la Lamborgini Aventador est effectivement une voiture avec des carat√©ristiques atypiques

    # mod√®le sans les 3 points influents
    x = X_wltp_scaled_train.drop(X_wltp_scaled_train.loc[ind].index, axis=0)
    y = y_wltp_train.drop(y_wltp_train.loc[ind].index, axis=0)

    # entrainement du mod√®le de r√©gression lin√©aire&√©
    model_wltp = sm.OLS(y, sm.add_constant(x, prepend=False)).fit()
    print(model_wltp.summary())

    # analyse graphique de l'influence √† partir de la distance de Cook
    influence = model_wltp.get_influence()
    (c, p) = influence.cooks_distance # c : distance et p : p-value

    plt.stem(np.arange(len(c)), c, markerfmt=",")
    plt.ylim(0,0.03)
    # plt.axhline(y = 3*c.mean(),color="r",linewidth=1)

    plt.title('Points influents : exclusion des Lamborghini Aventador')
    plt.ylabel('Distance de Cook')
    st.pyplot()

if model == 'R√©gression lin√©aire r√©gularis√©e (ElasticNet)':
    ## points influents et significativit√© des coefficients avec statsmodel 
    y = y_wltp_train
    x = X_wltp_scaled_train

    # entrainement du mod√®le de r√©gression lin√©aire
    model_wltp = sm.OLS(y, sm.add_constant(x, prepend=False)).fit()
    print(model_wltp.summary())
    
    influence = model_wltp.get_influence()
    (c, p) = influence.cooks_distance # c : distance et p : p-value
    
    # visualisation des 3 points tr√®s influents
    df_cooks = pd.DataFrame(c, columns = ['cook'], index = X_wltp_scaled_train.index)
    ind = df_cooks.loc[df_cooks['cook']>0.08].index


    # mod√®le sans les 3 points influents
    x = X_wltp_scaled_train.drop(X_wltp_scaled_train.loc[ind].index, axis=0)
    y = y_wltp_train.drop(y_wltp_train.loc[ind].index, axis=0)
    

    st.subheader('R√©gression lin√©aire r√©gularis√©e - ElasticNet')
    st.write("Compte tenu des corr√©lations fortes observ√©es entre certaines caract√©ristiques techniques des v√©hicules, une r√©gularisation est appliqu√©e. Un mod√®le Elastic Net est impl√©ment√© avec une optimisation des param√®tres de r√©gularisation √† partir d‚Äôune m√©thode grid search.")
    
    ## Recherche des param√®tres les plus explicatifs avec une r√©gression ElasticNet
    ## reprise des donn√©es sans les 3 points influents
    x = X_wltp_scaled_train.drop(X_wltp_scaled_train.loc[ind].index, axis=0)
    y = y_wltp_train.drop(y_wltp_train.loc[ind].index, axis=0)

    model_en = ElasticNetCV(cv=10,
                            l1_ratio = (0.1, 0.25, 0.5, 0.75, 0.99),
                            n_alphas = 200,
                            random_state=33)

    model_en.fit(x, y)
    st.write('Alpha s√©lectionn√© par validation crois√©e :', model_en.alpha_.round(4), 'l1_ratio s√©lectionn√© par validation crois√©e :', model_en.l1_ratio_)

    pred_train = model_en.predict(x)
    pred_test = model_en.predict(X_wltp_scaled_test)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.write('  - R¬≤ train :', model_en.score(x, y).round(4))
        st.write('  - R¬≤ test :', model_en.score(X_wltp_scaled_test, y_wltp_test).round(4))
    with col2:
        st.write('  - RMSE train :', np.sqrt(mean_squared_error(y, pred_train)).round(3))
        st.write('  - RMSE test :', np.sqrt(mean_squared_error(y_wltp_test, pred_test)).round(3))
    with col3:
        st.write('  - MAE train :', mean_absolute_error(pred_train, y).round(3))
        st.write('  - MAE test :', mean_absolute_error(pred_test, y_wltp_test).round(3))
    
    # Coefficients
    lr_wltp = LinearRegression()
    lr_wltp.fit(X_wltp_scaled_train, y_wltp_train)
    st.markdown("#### Comparaison des coefficients de r√©gression entre le mod√®le simple et r√©gularis√©")
    coeffs = pd.DataFrame({'mod√®le simple': lr_wltp.coef_}, index=feats_wltp[options].columns) # mod√®le lin√©aire
    coeffs = coeffs.join(pd.DataFrame({'mod√®le r√©gularis√©': model_en.coef_}, index=feats_wltp[options].columns)) # mod√®le r√©gularis√©
    coeffs.sort_values(by='mod√®le simple', inplace=True)

    coeffs.plot.barh(figsize=(14, 5))
    plt.subplots_adjust(left=0.3)
    plt.title("Coefficents de r√©gression lin√©aire\n")
    st.pyplot()
    
    st.write("La repr√©sentation graphique des coefficients obtenus pour le mod√®le simple et le mod√®le r√©gularis√© montre √† la fois qu‚Äôaucun param√®tre n‚Äôest exclu du mod√®le, et que les valeurs des coefficients restent tr√®s proches. N√©anmoins, le mod√®le p√©nalis√© permet bien de diminuer la diff√©rence des RMSE entre donn√©es d'entra√Ænement et donn√©es test.")

if model == 'XGBoost':
    st.subheader("XGBoost")
    st.write("XGBoost est un mod√®le d‚Äôensemble tr√®s utilis√© pour ses qualit√©s pr√©dictives mais comprend un nombre tr√®s important d‚Äôhyperparam√®tres √† optimiser.")
    st.write("Une m√©thode d'optimisation s√©quentielle des param√®tres a √©t√© adopt√©e : les param√®tres sont optimis√©s de fa√ßon isol√©e ou par paire, les mod√®les suivants int√©grant les param√®tres s√©lectionn√©s dans les √©tapes pr√©c√©dentes.")

    with st.expander("Afficher les param√®tres s√©lectionn√©s apr√®s optimisation"):
        st.success("objective = 'regsquarederror',  eval_metric = 'rmse',  learning_rate = 0.005,  n_estimators = 6000,  max_depth = 11, min_child_weight = 3,  gamma = 20,  subsample = 0.8,  colsample_bytree = 1,  reg_alpha = 0.35,  reg_lambda = 1.8, random_state = 1")
        
    st.write('  - Coefficient de d√©termination du mod√®le :', 0.994)
    st.write('  - Coefficient de d√©termination des donn√©es test :', 0.98)
    st.write('  - RMSE train :', 3.07)
    st.write('  - RMSE test :', 5.5)
    st.write('  - MAE train :', 2.24)
    st.write('  - MAE test :', 3.79)
    
    st.warning("En raison d'un temps d'ex√©cution tr√®s long, le mod√®le a √©t√© ex√©cut√© en amont et les scores pr√©sent√©s sont donc fig√©s.")
    
    st.markdown("#### Importance des variables selon les valeurs de Shap")
    
    from PIL import Image
    shap = Image.open('shap_regression.png')
    st.image(shap)